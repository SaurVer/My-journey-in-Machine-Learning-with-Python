{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('uscrime.txt',delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>So</th>\n",
       "      <th>Ed</th>\n",
       "      <th>Po1</th>\n",
       "      <th>Po2</th>\n",
       "      <th>LF</th>\n",
       "      <th>M.F</th>\n",
       "      <th>Pop</th>\n",
       "      <th>NW</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Ineq</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Time</th>\n",
       "      <th>Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>95.0</td>\n",
       "      <td>33</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.108</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3940</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.084602</td>\n",
       "      <td>26.2011</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.583</td>\n",
       "      <td>101.2</td>\n",
       "      <td>13</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.096</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5570</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.029599</td>\n",
       "      <td>25.2999</td>\n",
       "      <td>1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.533</td>\n",
       "      <td>96.9</td>\n",
       "      <td>18</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.094</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3180</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.083401</td>\n",
       "      <td>24.3006</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.6</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.577</td>\n",
       "      <td>99.4</td>\n",
       "      <td>157</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6730</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.015801</td>\n",
       "      <td>29.9012</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.591</td>\n",
       "      <td>98.5</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5780</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.041399</td>\n",
       "      <td>21.2998</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      M  So    Ed   Po1   Po2     LF    M.F  Pop    NW     U1   U2  Wealth  \\\n",
       "0  15.1   1   9.1   5.8   5.6  0.510   95.0   33  30.1  0.108  4.1    3940   \n",
       "1  14.3   0  11.3  10.3   9.5  0.583  101.2   13  10.2  0.096  3.6    5570   \n",
       "2  14.2   1   8.9   4.5   4.4  0.533   96.9   18  21.9  0.094  3.3    3180   \n",
       "3  13.6   0  12.1  14.9  14.1  0.577   99.4  157   8.0  0.102  3.9    6730   \n",
       "4  14.1   0  12.1  10.9  10.1  0.591   98.5   18   3.0  0.091  2.0    5780   \n",
       "\n",
       "   Ineq      Prob     Time  Crime  \n",
       "0  26.1  0.084602  26.2011    791  \n",
       "1  19.4  0.029599  25.2999   1635  \n",
       "2  25.0  0.083401  24.3006    578  \n",
       "3  16.7  0.015801  29.9012   1969  \n",
       "4  17.4  0.041399  21.2998   1234  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To handle categorical data we need to encode them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataset=dataset.drop('Pop',axis=1), it was previously dropped because the coefficient associated with this parameter was too samll.(sklearn linear regression model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset.iloc[:,:-1].values\n",
    "y=dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>So</th>\n",
       "      <th>Ed</th>\n",
       "      <th>Po1</th>\n",
       "      <th>Po2</th>\n",
       "      <th>LF</th>\n",
       "      <th>M.F</th>\n",
       "      <th>NW</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Ineq</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Time</th>\n",
       "      <th>Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>95.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.108</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3940</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.084602</td>\n",
       "      <td>26.2011</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.583</td>\n",
       "      <td>101.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.096</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5570</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.029599</td>\n",
       "      <td>25.2999</td>\n",
       "      <td>1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.533</td>\n",
       "      <td>96.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.094</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3180</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.083401</td>\n",
       "      <td>24.3006</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.6</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.577</td>\n",
       "      <td>99.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6730</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.015801</td>\n",
       "      <td>29.9012</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.591</td>\n",
       "      <td>98.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5780</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.041399</td>\n",
       "      <td>21.2998</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.547</td>\n",
       "      <td>96.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.084</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6890</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.034201</td>\n",
       "      <td>20.9995</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.7</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.519</td>\n",
       "      <td>98.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.097</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6200</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>20.6993</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>11.5</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.542</td>\n",
       "      <td>96.9</td>\n",
       "      <td>17.9</td>\n",
       "      <td>0.079</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4720</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.040099</td>\n",
       "      <td>24.5988</td>\n",
       "      <td>1555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.7</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.553</td>\n",
       "      <td>95.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.081</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4210</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0.071697</td>\n",
       "      <td>29.4001</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.632</td>\n",
       "      <td>102.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5260</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.044498</td>\n",
       "      <td>19.5994</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.4</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>12.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.580</td>\n",
       "      <td>96.6</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.077</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6570</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>41.6000</td>\n",
       "      <td>1674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.4</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.595</td>\n",
       "      <td>97.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.083</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5800</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0.031201</td>\n",
       "      <td>34.2984</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.8</td>\n",
       "      <td>0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>97.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5070</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.045302</td>\n",
       "      <td>36.2993</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.5</td>\n",
       "      <td>0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.595</td>\n",
       "      <td>98.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.077</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5290</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>21.5010</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.530</td>\n",
       "      <td>98.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.092</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4050</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>22.7008</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.497</td>\n",
       "      <td>95.6</td>\n",
       "      <td>32.1</td>\n",
       "      <td>0.116</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4270</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.052099</td>\n",
       "      <td>26.0991</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.537</td>\n",
       "      <td>97.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.114</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4870</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0.076299</td>\n",
       "      <td>19.1002</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.537</td>\n",
       "      <td>97.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.089</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6310</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.119804</td>\n",
       "      <td>18.1996</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>12.8</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.536</td>\n",
       "      <td>93.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.078</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6270</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.019099</td>\n",
       "      <td>24.9008</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.567</td>\n",
       "      <td>98.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.130</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6260</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0.034801</td>\n",
       "      <td>26.4010</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12.6</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.602</td>\n",
       "      <td>98.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.102</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5570</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>37.5998</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15.7</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.512</td>\n",
       "      <td>96.2</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.097</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2880</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.089502</td>\n",
       "      <td>37.0994</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13.2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.564</td>\n",
       "      <td>95.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.083</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5130</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>25.1989</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.574</td>\n",
       "      <td>103.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.142</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5400</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.041598</td>\n",
       "      <td>17.6000</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.641</td>\n",
       "      <td>98.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.070</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4860</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.069197</td>\n",
       "      <td>21.9003</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.631</td>\n",
       "      <td>107.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.102</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6740</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.041698</td>\n",
       "      <td>22.1005</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.540</td>\n",
       "      <td>96.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.080</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5640</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.036099</td>\n",
       "      <td>28.4999</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15.2</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.571</td>\n",
       "      <td>101.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.103</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5370</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.038201</td>\n",
       "      <td>25.8006</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11.9</td>\n",
       "      <td>0</td>\n",
       "      <td>10.7</td>\n",
       "      <td>16.6</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0.521</td>\n",
       "      <td>93.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.092</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6370</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>36.7009</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16.6</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.521</td>\n",
       "      <td>97.3</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0.072</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3960</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.075298</td>\n",
       "      <td>28.3011</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.535</td>\n",
       "      <td>104.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4530</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.041999</td>\n",
       "      <td>21.7998</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.586</td>\n",
       "      <td>96.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.105</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6170</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0.042698</td>\n",
       "      <td>30.9014</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14.7</td>\n",
       "      <td>1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.560</td>\n",
       "      <td>97.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.076</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4620</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.049499</td>\n",
       "      <td>25.5005</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12.6</td>\n",
       "      <td>0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.542</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.102</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5890</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0.040799</td>\n",
       "      <td>21.6997</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.526</td>\n",
       "      <td>94.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.124</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5720</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>37.4011</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.531</td>\n",
       "      <td>96.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.087</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5590</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>44.0004</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>17.7</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.638</td>\n",
       "      <td>97.4</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3820</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0.045198</td>\n",
       "      <td>31.6995</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.3</td>\n",
       "      <td>0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.599</td>\n",
       "      <td>102.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.099</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4250</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.053998</td>\n",
       "      <td>16.6999</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>14.9</td>\n",
       "      <td>1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.515</td>\n",
       "      <td>95.3</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.086</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3950</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.047099</td>\n",
       "      <td>27.3004</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.560</td>\n",
       "      <td>98.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.088</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4880</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0.038801</td>\n",
       "      <td>29.3004</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>14.8</td>\n",
       "      <td>0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.601</td>\n",
       "      <td>99.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.084</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5900</td>\n",
       "      <td>14.4</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>30.0001</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>14.1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.523</td>\n",
       "      <td>96.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.107</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4890</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.088904</td>\n",
       "      <td>12.1996</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16.2</td>\n",
       "      <td>1</td>\n",
       "      <td>9.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.522</td>\n",
       "      <td>99.6</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.073</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4960</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>31.9989</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>13.6</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.574</td>\n",
       "      <td>101.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.111</td>\n",
       "      <td>3.7</td>\n",
       "      <td>6220</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>30.0001</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>13.9</td>\n",
       "      <td>1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.480</td>\n",
       "      <td>96.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.135</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4570</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0.056202</td>\n",
       "      <td>32.5996</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>12.6</td>\n",
       "      <td>0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.599</td>\n",
       "      <td>98.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.078</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5930</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.046598</td>\n",
       "      <td>16.6999</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.623</td>\n",
       "      <td>104.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.113</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5880</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.052802</td>\n",
       "      <td>16.0997</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       M  So    Ed   Po1   Po2     LF    M.F    NW     U1   U2  Wealth  Ineq  \\\n",
       "0   15.1   1   9.1   5.8   5.6  0.510   95.0  30.1  0.108  4.1    3940  26.1   \n",
       "1   14.3   0  11.3  10.3   9.5  0.583  101.2  10.2  0.096  3.6    5570  19.4   \n",
       "2   14.2   1   8.9   4.5   4.4  0.533   96.9  21.9  0.094  3.3    3180  25.0   \n",
       "3   13.6   0  12.1  14.9  14.1  0.577   99.4   8.0  0.102  3.9    6730  16.7   \n",
       "4   14.1   0  12.1  10.9  10.1  0.591   98.5   3.0  0.091  2.0    5780  17.4   \n",
       "5   12.1   0  11.0  11.8  11.5  0.547   96.4   4.4  0.084  2.9    6890  12.6   \n",
       "6   12.7   1  11.1   8.2   7.9  0.519   98.2  13.9  0.097  3.8    6200  16.8   \n",
       "7   13.1   1  10.9  11.5  10.9  0.542   96.9  17.9  0.079  3.5    4720  20.6   \n",
       "8   15.7   1   9.0   6.5   6.2  0.553   95.5  28.6  0.081  2.8    4210  23.9   \n",
       "9   14.0   0  11.8   7.1   6.8  0.632  102.9   1.5  0.100  2.4    5260  17.4   \n",
       "10  12.4   0  10.5  12.1  11.6  0.580   96.6  10.6  0.077  3.5    6570  17.0   \n",
       "11  13.4   0  10.8   7.5   7.1  0.595   97.2   5.9  0.083  3.1    5800  17.2   \n",
       "12  12.8   0  11.3   6.7   6.0  0.624   97.2   1.0  0.077  2.5    5070  20.6   \n",
       "13  13.5   0  11.7   6.2   6.1  0.595   98.6   4.6  0.077  2.7    5290  19.0   \n",
       "14  15.2   1   8.7   5.7   5.3  0.530   98.6   7.2  0.092  4.3    4050  26.4   \n",
       "15  14.2   1   8.8   8.1   7.7  0.497   95.6  32.1  0.116  4.7    4270  24.7   \n",
       "16  14.3   0  11.0   6.6   6.3  0.537   97.7   0.6  0.114  3.5    4870  16.6   \n",
       "17  13.5   1  10.4  12.3  11.5  0.537   97.8  17.0  0.089  3.4    6310  16.5   \n",
       "18  13.0   0  11.6  12.8  12.8  0.536   93.4   2.4  0.078  3.4    6270  13.5   \n",
       "19  12.5   0  10.8  11.3  10.5  0.567   98.5   9.4  0.130  5.8    6260  16.6   \n",
       "20  12.6   0  10.8   7.4   6.7  0.602   98.4   1.2  0.102  3.3    5570  19.5   \n",
       "21  15.7   1   8.9   4.7   4.4  0.512   96.2  42.3  0.097  3.4    2880  27.6   \n",
       "22  13.2   0   9.6   8.7   8.3  0.564   95.3   9.2  0.083  3.2    5130  22.7   \n",
       "23  13.1   0  11.6   7.8   7.3  0.574  103.8   3.6  0.142  4.2    5400  17.6   \n",
       "24  13.0   0  11.6   6.3   5.7  0.641   98.4   2.6  0.070  2.1    4860  19.6   \n",
       "25  13.1   0  12.1  16.0  14.3  0.631  107.1   7.7  0.102  4.1    6740  15.2   \n",
       "26  13.5   0  10.9   6.9   7.1  0.540   96.5   0.4  0.080  2.2    5640  13.9   \n",
       "27  15.2   0  11.2   8.2   7.6  0.571  101.8   7.9  0.103  2.8    5370  21.5   \n",
       "28  11.9   0  10.7  16.6  15.7  0.521   93.8   8.9  0.092  3.6    6370  15.4   \n",
       "29  16.6   1   8.9   5.8   5.4  0.521   97.3  25.4  0.072  2.6    3960  23.7   \n",
       "30  14.0   0   9.3   5.5   5.4  0.535  104.5   2.0  0.135  4.0    4530  20.0   \n",
       "31  12.5   0  10.9   9.0   8.1  0.586   96.4   8.2  0.105  4.3    6170  16.3   \n",
       "32  14.7   1  10.4   6.3   6.4  0.560   97.2   9.5  0.076  2.4    4620  23.3   \n",
       "33  12.6   0  11.8   9.7   9.7  0.542   99.0   2.1  0.102  3.5    5890  16.6   \n",
       "34  12.3   0  10.2   9.7   8.7  0.526   94.8   7.6  0.124  5.0    5720  15.8   \n",
       "35  15.0   0  10.0  10.9   9.8  0.531   96.4   2.4  0.087  3.8    5590  15.3   \n",
       "36  17.7   1   8.7   5.8   5.6  0.638   97.4  34.9  0.076  2.8    3820  25.4   \n",
       "37  13.3   0  10.4   5.1   4.7  0.599  102.4   4.0  0.099  2.7    4250  22.5   \n",
       "38  14.9   1   8.8   6.1   5.4  0.515   95.3  16.5  0.086  3.5    3950  25.1   \n",
       "39  14.5   1  10.4   8.2   7.4  0.560   98.1  12.6  0.088  3.1    4880  22.8   \n",
       "40  14.8   0  12.2   7.2   6.6  0.601   99.8   1.9  0.084  2.0    5900  14.4   \n",
       "41  14.1   0  10.9   5.6   5.4  0.523   96.8   0.2  0.107  3.7    4890  17.0   \n",
       "42  16.2   1   9.9   7.5   7.0  0.522   99.6  20.8  0.073  2.7    4960  22.4   \n",
       "43  13.6   0  12.1   9.5   9.6  0.574  101.2   3.6  0.111  3.7    6220  16.2   \n",
       "44  13.9   1   8.8   4.6   4.1  0.480   96.8   4.9  0.135  5.3    4570  24.9   \n",
       "45  12.6   0  10.4  10.6   9.7  0.599   98.9   2.4  0.078  2.5    5930  17.1   \n",
       "46  13.0   0  12.1   9.0   9.1  0.623  104.9   2.2  0.113  4.0    5880  16.0   \n",
       "\n",
       "        Prob     Time  Crime  \n",
       "0   0.084602  26.2011    791  \n",
       "1   0.029599  25.2999   1635  \n",
       "2   0.083401  24.3006    578  \n",
       "3   0.015801  29.9012   1969  \n",
       "4   0.041399  21.2998   1234  \n",
       "5   0.034201  20.9995    682  \n",
       "6   0.042100  20.6993    963  \n",
       "7   0.040099  24.5988   1555  \n",
       "8   0.071697  29.4001    856  \n",
       "9   0.044498  19.5994    705  \n",
       "10  0.016201  41.6000   1674  \n",
       "11  0.031201  34.2984    849  \n",
       "12  0.045302  36.2993    511  \n",
       "13  0.053200  21.5010    664  \n",
       "14  0.069100  22.7008    798  \n",
       "15  0.052099  26.0991    946  \n",
       "16  0.076299  19.1002    539  \n",
       "17  0.119804  18.1996    929  \n",
       "18  0.019099  24.9008    750  \n",
       "19  0.034801  26.4010   1225  \n",
       "20  0.022800  37.5998    742  \n",
       "21  0.089502  37.0994    439  \n",
       "22  0.030700  25.1989   1216  \n",
       "23  0.041598  17.6000    968  \n",
       "24  0.069197  21.9003    523  \n",
       "25  0.041698  22.1005   1993  \n",
       "26  0.036099  28.4999    342  \n",
       "27  0.038201  25.8006   1216  \n",
       "28  0.023400  36.7009   1043  \n",
       "29  0.075298  28.3011    696  \n",
       "30  0.041999  21.7998    373  \n",
       "31  0.042698  30.9014    754  \n",
       "32  0.049499  25.5005   1072  \n",
       "33  0.040799  21.6997    923  \n",
       "34  0.020700  37.4011    653  \n",
       "35  0.006900  44.0004   1272  \n",
       "36  0.045198  31.6995    831  \n",
       "37  0.053998  16.6999    566  \n",
       "38  0.047099  27.3004    826  \n",
       "39  0.038801  29.3004   1151  \n",
       "40  0.025100  30.0001    880  \n",
       "41  0.088904  12.1996    542  \n",
       "42  0.054902  31.9989    823  \n",
       "43  0.028100  30.0001   1030  \n",
       "44  0.056202  32.5996    455  \n",
       "45  0.046598  16.6999    508  \n",
       "46  0.052802  16.0997    849  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder=OneHotEncoder(categorical_features=[1])\n",
    "x=onehotencoder.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling required, this can also be done prior to the splitting into test, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_x=StandardScaler()\n",
    "x_train=sc_x.fit_transform(x_train)\n",
    "x_test=sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1389,  544,  426,  566,  945, 1221, 1157,  946,  916,  775,  765,\n",
       "        602])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1555,  742,  373,  542,  826,  750,  823,  508, 1674, 1072,  754,\n",
       "        849], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111148.94269629575"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = metrics.mean_squared_error(y_test, y_pred)\n",
    "r2 = metrics.r2_score(y_test, y_pred)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2111700641047921"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: [  14.86830047  -14.86830047  177.47455399  226.22537559  979.39458617\n",
      " -692.81622516  -78.24818895   35.10689332   54.02312083 -118.80981958\n",
      "  157.05828816   47.70303178  229.64562695 -154.00612355 -129.91503458]\n",
      "Intercept: 916.3142857142855\n"
     ]
    }
   ],
   "source": [
    "print('Slope:' ,regressor.coef_)\n",
    "print('Intercept:', regressor.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are gonna use statsmodel linear regeression because we couldn't see the p-values in the skleearn packagew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=sm.add_constant(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1125.74160035,  811.23454704, 1721.90556212,  820.80577175,\n",
       "        434.01268121,  821.87056453,  720.75687755, 1263.80169144,\n",
       "        933.8777922 , 1218.21126306,  208.04737273,  589.25453634])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=sm.OLS(y_train,x_train).fit()\n",
    "x_test = sm.add_constant(x_test)\n",
    "y_pred=model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1234,  511, 1969,  653,  566,  455,  929, 1555, 1216,  750,  578,\n",
       "        856], dtype=int64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 04 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>7.80e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:50:03</td>     <th>  Log-Likelihood:    </th> <td> -222.77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    35</td>      <th>  AIC:               </th> <td>   477.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    19</td>      <th>  BIC:               </th> <td>   502.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  893.3429</td> <td>   32.255</td> <td>   27.696</td> <td> 0.000</td> <td>  825.832</td> <td>  960.854</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -3.3116</td> <td>   43.885</td> <td>   -0.075</td> <td> 0.941</td> <td>  -95.163</td> <td>   88.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.3116</td> <td>   43.885</td> <td>    0.075</td> <td> 0.941</td> <td>  -88.540</td> <td>   95.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>  148.2717</td> <td>   68.392</td> <td>    2.168</td> <td> 0.043</td> <td>    5.126</td> <td>  291.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>  237.3085</td> <td>   80.948</td> <td>    2.932</td> <td> 0.009</td> <td>   67.882</td> <td>  406.735</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>  474.1561</td> <td>  294.316</td> <td>    1.611</td> <td> 0.124</td> <td> -141.855</td> <td> 1090.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td> -250.6535</td> <td>  304.695</td> <td>   -0.823</td> <td> 0.421</td> <td> -888.388</td> <td>  387.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>  -22.8197</td> <td>   61.861</td> <td>   -0.369</td> <td> 0.716</td> <td> -152.297</td> <td>  106.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    3.5147</td> <td>   71.784</td> <td>    0.049</td> <td> 0.961</td> <td> -146.731</td> <td>  153.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>  -62.7109</td> <td>   56.940</td> <td>   -1.101</td> <td> 0.284</td> <td> -181.887</td> <td>   56.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>  -18.0153</td> <td>   81.234</td> <td>   -0.222</td> <td> 0.827</td> <td> -188.040</td> <td>  152.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td> -102.5139</td> <td>   97.013</td> <td>   -1.057</td> <td> 0.304</td> <td> -305.564</td> <td>  100.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>  186.0261</td> <td>   79.795</td> <td>    2.331</td> <td> 0.031</td> <td>   19.014</td> <td>  353.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>  126.1251</td> <td>  151.404</td> <td>    0.833</td> <td> 0.415</td> <td> -190.767</td> <td>  443.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>  299.2272</td> <td>  114.988</td> <td>    2.602</td> <td> 0.018</td> <td>   58.555</td> <td>  539.899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td> -100.5243</td> <td>   78.924</td> <td>   -1.274</td> <td> 0.218</td> <td> -265.714</td> <td>   64.666</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>   18.1236</td> <td>   68.179</td> <td>    0.266</td> <td> 0.793</td> <td> -124.576</td> <td>  160.823</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.407</td> <th>  Durbin-Watson:     </th> <td>   2.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  17.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.172</td> <th>  Prob(JB):          </th> <td>0.000178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.518</td> <th>  Cond. No.          </th> <td>5.00e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 9.83e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.844\n",
       "Model:                            OLS   Adj. R-squared:                  0.722\n",
       "Method:                 Least Squares   F-statistic:                     6.874\n",
       "Date:                Thu, 04 Apr 2019   Prob (F-statistic):           7.80e-05\n",
       "Time:                        10:50:03   Log-Likelihood:                -222.77\n",
       "No. Observations:                  35   AIC:                             477.5\n",
       "Df Residuals:                      19   BIC:                             502.4\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        893.3429     32.255     27.696      0.000     825.832     960.854\n",
       "x1            -3.3116     43.885     -0.075      0.941     -95.163      88.540\n",
       "x2             3.3116     43.885      0.075      0.941     -88.540      95.163\n",
       "x3           148.2717     68.392      2.168      0.043       5.126     291.418\n",
       "x4           237.3085     80.948      2.932      0.009      67.882     406.735\n",
       "x5           474.1561    294.316      1.611      0.124    -141.855    1090.167\n",
       "x6          -250.6535    304.695     -0.823      0.421    -888.388     387.081\n",
       "x7           -22.8197     61.861     -0.369      0.716    -152.297     106.657\n",
       "x8             3.5147     71.784      0.049      0.961    -146.731     153.761\n",
       "x9           -62.7109     56.940     -1.101      0.284    -181.887      56.465\n",
       "x10          -18.0153     81.234     -0.222      0.827    -188.040     152.009\n",
       "x11         -102.5139     97.013     -1.057      0.304    -305.564     100.536\n",
       "x12          186.0261     79.795      2.331      0.031      19.014     353.038\n",
       "x13          126.1251    151.404      0.833      0.415    -190.767     443.017\n",
       "x14          299.2272    114.988      2.602      0.018      58.555     539.899\n",
       "x15         -100.5243     78.924     -1.274      0.218    -265.714      64.666\n",
       "x16           18.1236     68.179      0.266      0.793    -124.576     160.823\n",
       "==============================================================================\n",
       "Omnibus:                       14.407   Durbin-Watson:                   2.086\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               17.267\n",
       "Skew:                           1.172   Prob(JB):                     0.000178\n",
       "Kurtosis:                       5.518   Cond. No.                     5.00e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 9.83e-32. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can remove the parameters whose p values are greater than .05\n",
    "#These coefficients are x1,x2,x5 to x11,x13,x15,x16.\n",
    "#Lets load the data again and do this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=pd.read_csv('uscrime.txt',delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>So</th>\n",
       "      <th>Ed</th>\n",
       "      <th>Po1</th>\n",
       "      <th>Po2</th>\n",
       "      <th>LF</th>\n",
       "      <th>M.F</th>\n",
       "      <th>Pop</th>\n",
       "      <th>NW</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Ineq</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Time</th>\n",
       "      <th>Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>95.0</td>\n",
       "      <td>33</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.108</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3940</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.084602</td>\n",
       "      <td>26.2011</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.583</td>\n",
       "      <td>101.2</td>\n",
       "      <td>13</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.096</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5570</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0.029599</td>\n",
       "      <td>25.2999</td>\n",
       "      <td>1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.533</td>\n",
       "      <td>96.9</td>\n",
       "      <td>18</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.094</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3180</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.083401</td>\n",
       "      <td>24.3006</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.6</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>14.9</td>\n",
       "      <td>14.1</td>\n",
       "      <td>0.577</td>\n",
       "      <td>99.4</td>\n",
       "      <td>157</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6730</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.015801</td>\n",
       "      <td>29.9012</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.591</td>\n",
       "      <td>98.5</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5780</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.041399</td>\n",
       "      <td>21.2998</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      M  So    Ed   Po1   Po2     LF    M.F  Pop    NW     U1   U2  Wealth  \\\n",
       "0  15.1   1   9.1   5.8   5.6  0.510   95.0   33  30.1  0.108  4.1    3940   \n",
       "1  14.3   0  11.3  10.3   9.5  0.583  101.2   13  10.2  0.096  3.6    5570   \n",
       "2  14.2   1   8.9   4.5   4.4  0.533   96.9   18  21.9  0.094  3.3    3180   \n",
       "3  13.6   0  12.1  14.9  14.1  0.577   99.4  157   8.0  0.102  3.9    6730   \n",
       "4  14.1   0  12.1  10.9  10.1  0.591   98.5   18   3.0  0.091  2.0    5780   \n",
       "\n",
       "   Ineq      Prob     Time  Crime  \n",
       "0  26.1  0.084602  26.2011    791  \n",
       "1  19.4  0.029599  25.2999   1635  \n",
       "2  25.0  0.083401  24.3006    578  \n",
       "3  16.7  0.015801  29.9012   1969  \n",
       "4  17.4  0.041399  21.2998   1234  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.head()#M,Ed,U1,Wealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=dataset1[['M','Ed','U2','Wealth','Ineq','Crime']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>Ed</th>\n",
       "      <th>U2</th>\n",
       "      <th>Wealth</th>\n",
       "      <th>Ineq</th>\n",
       "      <th>Crime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3940</td>\n",
       "      <td>26.1</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5570</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3180</td>\n",
       "      <td>25.0</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.6</td>\n",
       "      <td>12.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6730</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5780</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      M    Ed   U2  Wealth  Ineq  Crime\n",
       "0  15.1   9.1  4.1    3940  26.1    791\n",
       "1  14.3  11.3  3.6    5570  19.4   1635\n",
       "2  14.2   8.9  3.3    3180  25.0    578\n",
       "3  13.6  12.1  3.9    6730  16.7   1969\n",
       "4  14.1  12.1  2.0    5780  17.4   1234"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset1.iloc[:,0:5].values\n",
    "Y=dataset1.iloc[:,-1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data after splitting into tests and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12, 5), (35, 5), (12,), (35,))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape,X_train.shape,Y_test.shape,Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc_x=StandardScaler()\n",
    "#X_train=sc_x.fit_transform(X_train)\n",
    "#X_test=sc_x.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have our package import done\n",
    "X_test = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=sm.add_constant(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=sm.OLS(Y_train,X_train).fit()\n",
    "Y_pred=Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 525.79799796,  860.11081845,  970.85566721, 1131.74001239,\n",
       "       1031.11068007,  988.41356929,  728.50452888,  916.30242559,\n",
       "       1226.75182469, 1082.38196219, 1032.45435297,  843.86934001])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 04 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>0.000270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:59:12</td>     <th>  Log-Likelihood:    </th> <td> -247.44</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    35</td>      <th>  AIC:               </th> <td>   506.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    29</td>      <th>  BIC:               </th> <td>   516.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-7524.7003</td> <td> 1732.055</td> <td>   -4.344</td> <td> 0.000</td> <td>-1.11e+04</td> <td>-3982.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  126.1991</td> <td>   59.592</td> <td>    2.118</td> <td> 0.043</td> <td>    4.319</td> <td>  248.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  152.5892</td> <td>   79.461</td> <td>    1.920</td> <td> 0.065</td> <td>   -9.927</td> <td>  315.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>  108.3725</td> <td>   69.329</td> <td>    1.563</td> <td> 0.129</td> <td>  -33.420</td> <td>  250.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    0.5202</td> <td>    0.122</td> <td>    4.259</td> <td> 0.000</td> <td>    0.270</td> <td>    0.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>  103.7402</td> <td>   30.225</td> <td>    3.432</td> <td> 0.002</td> <td>   41.923</td> <td>  165.558</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.982</td> <th>  Durbin-Watson:     </th> <td>   2.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.137</td> <th>  Jarque-Bera (JB):  </th> <td>   2.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.619</td> <th>  Prob(JB):          </th> <td>   0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.534</td> <th>  Cond. No.          </th> <td>1.78e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.78e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.539\n",
       "Model:                            OLS   Adj. R-squared:                  0.459\n",
       "Method:                 Least Squares   F-statistic:                     6.775\n",
       "Date:                Thu, 04 Apr 2019   Prob (F-statistic):           0.000270\n",
       "Time:                        11:59:12   Log-Likelihood:                -247.44\n",
       "No. Observations:                  35   AIC:                             506.9\n",
       "Df Residuals:                      29   BIC:                             516.2\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -7524.7003   1732.055     -4.344      0.000   -1.11e+04   -3982.249\n",
       "x1           126.1991     59.592      2.118      0.043       4.319     248.079\n",
       "x2           152.5892     79.461      1.920      0.065      -9.927     315.106\n",
       "x3           108.3725     69.329      1.563      0.129     -33.420     250.165\n",
       "x4             0.5202      0.122      4.259      0.000       0.270       0.770\n",
       "x5           103.7402     30.225      3.432      0.002      41.923     165.558\n",
       "==============================================================================\n",
       "Omnibus:                        3.982   Durbin-Watson:                   2.746\n",
       "Prob(Omnibus):                  0.137   Jarque-Bera (JB):                2.650\n",
       "Skew:                           0.619   Prob(JB):                        0.266\n",
       "Kurtosis:                       3.534   Cond. No.                     1.78e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.78e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion- I started with multiple Linear Regression in Sklearn package and removed the insignificant variable by looking at its coefficients(slope) but there I couldn't find the p-value, so I switched to the stats model OLS, there I trained the model on the whole dataset with scaling and One Hot encoding for the categorical data. \n",
    " # Here I found several variables with p-value> .05, that means they are insignificant(not all the time), I removed them as well and then trained the model again, later I found those variable had p-value>.05. and r2 was too small. Not a good success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAURABH\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Let us now use cross validation also\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAURABH\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\SAURABH\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\SAURABH\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\SAURABH\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\SAURABH\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\SAURABH\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\SAURABH\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\SAURABH\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\SAURABH\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\SAURABH\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py:100: DeprecationWarning: Scoring method mean_squared_error was renamed to neg_mean_squared_error in version 0.18 and will be removed in 0.20.\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "scores=cross_validation.cross_val_score(regressor,x_train,y_train,scoring='mean_squared_error',cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -59522.15713173,  -27169.37483577,  -55431.06730478,\n",
       "        -25740.24558352,  -60618.11831045,  -27108.67138296,\n",
       "        -35590.47540344, -214801.4154711 ,  -86327.40235301,\n",
       "        -57907.74454094])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=-scores.mean()# mean squared error\n",
    "\n",
    "rmse=np.sqrt(mse) # root mean squared error\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to use Cross validation to compare the model. We can compare Linear regression models(classification and regression models) with differen variables. Model1- can have different set of variable and the model2- will have other variables. we can find the model with the least mean of the root mean squared error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
